import gradio as gr
import httpx
import asyncio
import json
from datetime import datetime

API_BASE = "http://localhost:8000"


async def call_api(endpoint: str, data: dict = None, method: str = "GET"):
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            if method == "GET":
                response = await client.get(f"{API_BASE}{endpoint}")
            elif method == "POST":
                response = await client.post(f"{API_BASE}{endpoint}", json=data)
            elif method == "PUT":
                response = await client.put(f"{API_BASE}{endpoint}", json=data)
            elif method == "DELETE":
                response = await client.delete(f"{API_BASE}{endpoint}")
            else:
                return {"error": f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}"}

            if response.status_code == 200:
                return response.json()
            else:
                return {"error": f"APIé”™è¯¯: {response.status_code}", "status_code": response.status_code}
    except Exception as e:
        return {"error": str(e)}


def run_async(coro):
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                future = pool.submit(asyncio.run, coro)
                return future.result()
        else:
            return asyncio.run(coro)
    except RuntimeError:
        return asyncio.run(coro)


def get_memory_stats():
    result = run_async(call_api("/api/memories/stats"))
    if result.get("status") == "success":
        stats = result.get("statistics", {})
        total = stats.get("total", 0)
        permanent = stats.get("permanent", 0)
        long_term = stats.get("by_type", {}).get("long_term", 0)
        short_term = stats.get("by_type", {}).get("short_term", 0)
        return f"æ€»è®°å¿†: {total} | æ°¸ä¹…: {permanent} | é•¿æœŸ: {long_term} | çŸ­æœŸ: {short_term}"
    return "æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯"


def search_memories(query: str, memory_type: str = "all"):
    data = {
        "query": query if query else None,
        "memory_type": memory_type if memory_type != "all" else None,
        "limit": 20
    }
    result = run_async(call_api("/api/memories/search", data, "POST"))
    if result.get("status") == "success":
        memories = result.get("memories", [])
        if not memories:
            return "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†"
        return "\n\n".join([
            f"ã€{m.get('type', 'unknown')}ã€‘{m.get('content', '')[:300]}\né‡è¦æ€§: â­{m.get('importance', 3)} | {m.get('created_at', '')[:10]} | æ ‡ç­¾: {', '.join(m.get('tags', [])[:3])}"
            for m in memories
        ])
    return f"æœç´¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def add_memory(content: str, memory_type: str, importance: int, tags: str):
    data = {
        "content": content,
        "type": memory_type,
        "importance": importance,
        "tags": [t.strip() for t in tags.split(",") if t.strip()],
        "permanent": memory_type == "permanent"
    }
    result = run_async(call_api("/api/memories", data, "POST"))
    if result.get("status") == "success":
        return f"âœ“ è®°å¿†å·²æ·»åŠ  (ID: {result.get('memory_id')})"
    return f"âœ— æ·»åŠ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def search_memories_3d(query: str, memory_type: str = "all", weights: str = "default"):
    weight_map = {
        "default": [0.35, 0.25, 0.4],
        "importance": [0.5, 0.2, 0.3],
        "time": [0.2, 0.5, 0.3],
        "relevance": [0.3, 0.2, 0.5]
    }
    
    data = {
        "query": query if query else None,
        "memory_type": memory_type if memory_type != "all" else None,
        "weights": weight_map.get(weights, weight_map["default"]),
        "limit": 20
    }
    result = run_async(call_api("/api/memories/3d", data, "POST"))
    if result.get("status") == "success":
        memories = result.get("memories", [])
        if not memories:
            return "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†"
        
        output = []
        for m in memories:
            final_score = m.get("final_score", 0)
            component_scores = m.get("component_scores", {})
            output.append(
                f"ã€{m.get('type', 'unknown')}ã€‘{m.get('content', '')[:200]}\n"
                f"æœ€ç»ˆè¯„åˆ†: {final_score:.3f}\n"
                f"  - é‡è¦æ€§: {component_scores.get('importance', 0):.3f}\n"
                f"  - æ—¶é—´: {component_scores.get('time', 0):.3f}\n"
                f"  - ç›¸å…³æ€§: {component_scores.get('relevance', 0):.3f}\n"
                f"åˆ›å»ºæ—¶é—´: {m.get('created_at', '')[:10]}"
            )
        return "\n\n".join(output)
    return f"æœç´¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def recall_memory(memory_id: str, emotion_intensity: float = 0.5):
    try:
        mid = int(memory_id)
    except (ValueError, TypeError):
        return "âœ— æ— æ•ˆçš„è®°å¿†ID"
    
    data = {"emotion_intensity": emotion_intensity}
    result = run_async(call_api(f"/api/memories/recall/{mid}", data, "POST"))
    if result.get("status") == "success":
        memory = result.get("memory", {})
        reactivation_details = memory.get("reactivation_details", {})
        return (
            f"âœ“ è®°å¿†å·²å¬å›\n"
            f"å†…å®¹: {memory.get('content', '')[:200]}\n"
            f"é‡æ¿€æ´»æ¬¡æ•°: {memory.get('reactivation_count', 0)}\n"
            f"æƒ…æ„Ÿåˆ†æ•°: {memory.get('emotion_score', 0):.2f}\n"
            f"æ—¶é—´åˆ†å˜åŒ–: {reactivation_details.get('old_time_score', 0):.3f} â†’ {reactivation_details.get('new_time_score', 0):.3f}"
        )
    return f"âœ— å¬å›å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def get_permanent_memories():
    result = run_async(call_api("/api/memories/permanent"))
    if result.get("status") == "success":
        memories = result.get("memories", [])
        if not memories:
            return "æš‚æ— æ°¸ä¹…è®°å¿†"
        return "\n\n".join([
            f"ã€æ°¸ä¹…è®°å¿†ã€‘ID: {m.get('id', 'N/A')} | {m.get('content', '')[:200]} | é‡è¦æ€§: {m.get('importance_score', 1.0):.2f} | æ ‡ç­¾: {', '.join(m.get('tags', [])[:3])}"
            for m in memories
        ])
    return "è·å–å¤±è´¥"


def batch_add_memories(memories_text: str):
    try:
        import json
        memories = json.loads(memories_text)
    except:
        return "âœ— JSONæ ¼å¼é”™è¯¯"
    
    result = run_async(call_api("/api/memories/batch/write", {"memories": memories}, "POST"))
    if result.get("status") == "success":
        stats = result.get("result", {})
        return f"âœ“ æ‰¹é‡æ·»åŠ å®Œæˆ\næˆåŠŸ: {stats.get('success', 0)} | å¤±è´¥: {stats.get('failed', 0)}"
    return f"âœ— æ‰¹é‡æ·»åŠ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def get_decay_stats():
    result = run_async(call_api("/api/memories/decay-stats"))
    if result.get("status") == "success":
        stats = result.get("statistics", {})
        return (
            f"## è¡°å‡ç»Ÿè®¡\n"
            f"æ€»è®°å¿†: {stats.get('total_memories', 0)}\n"
            f"æ°¸ä¹…è®°å¿†: {stats.get('permanent_count', 0)}\n"
            f"éæ°¸ä¹…è®°å¿†: {stats.get('non_permanent_count', 0)}\n"
            f"å¹³å‡æ—¶é—´åˆ†: {stats.get('avg_time_score', 0):.4f}\n"
            f"å¹³å‡é‡è¦æ€§åˆ†: {stats.get('avg_importance_score', 0):.4f}\n\n"
            f"é‡æ¿€æ´»ç»Ÿè®¡:\n"
            f"  å·²é‡æ¿€æ´»: {stats.get('reactivation_stats', {}).get('reactivated_count', 0)}\n"
            f"  å¹³å‡é‡æ¿€æ´»æ¬¡æ•°: {stats.get('reactivation_stats', {}).get('avg_reactivation_count', 0):.2f}"
        )
    return "è·å–å¤±è´¥"


def get_secondary_commands():
    result = run_async(call_api("/api/memories/secondary/commands"))
    if result.get("status") == "success":
        commands = result.get("commands", {})
        output = []
        for cmd_name, cmd_info in commands.items():
            output.append(
                f"**{cmd_name}**\n"
                f"  æè¿°: {cmd_info.get('description', 'N/A')}\n"
                f"  å‚æ•°: {json.dumps(cmd_info.get('parameters', {}), ensure_ascii=False)}"
            )
        return "\n\n".join(output)
    return "è·å–å¤±è´¥"


def execute_secondary_command(command: str, parameters: str):
    try:
        params = json.loads(parameters) if parameters else {}
    except:
        params = {}
    
    data = {
        "command": command,
        "parameters": params
    }
    result = run_async(call_api("/api/memories/secondary/execute", data, "POST"))
    if result.get("status") == "success":
        cmd_result = result.get("result", {})
        return (
            f"âœ“ å‘½ä»¤æ‰§è¡ŒæˆåŠŸ\n"
            f"å‘½ä»¤: {cmd_result.get('command', 'N/A')}\n"
            f"çŠ¶æ€: {cmd_result.get('status', 'N/A')}\n"
            f"æ‰§è¡Œæ—¶é—´: {cmd_result.get('execution_time_ms', 0):.2f}ms\n"
            f"è¾“å‡º: {json.dumps(cmd_result.get('output', {}), ensure_ascii=False)}"
        )
    return f"âœ— å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def get_memory_list(memory_type: str = "all"):
    params = ""
    if memory_type != "all":
        params = f"?memory_type={memory_type}"
    result = run_async(call_api(f"/api/memories{params}"))
    if result.get("status") == "success":
        memories = result.get("memories", [])
        if not memories:
            return "æš‚æ— è®°å¿†"
        return "\n\n".join([
            f"ã€{m.get('type', 'unknown')}ã€‘{m.get('content', '')[:200]}...\nID: {m.get('id', 'N/A')} | é‡è¦æ€§: â­{m.get('importance', 3)}"
            for m in memories
        ])
    return "è·å–å¤±è´¥"


def delete_memory(memory_id: str):
    try:
        mid = int(memory_id)
    except (ValueError, TypeError):
        return "âœ— æ— æ•ˆçš„ID"
    result = run_async(call_api(f"/api/memories/{mid}", method="DELETE"))
    if result.get("status") == "success":
        return "âœ“ è®°å¿†å·²åˆ é™¤"
    return f"âœ— åˆ é™¤å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"


def chat_with_ai(message: str, history: list):
    if not message.strip():
        return history

    data = {"message": message, "stream": False}
    result = run_async(call_api("/chat", data, "POST"))

    if result.get("status") == "success":
        response = result.get("response", "")
        session_id = result.get("session_id", "")

        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response})

        return history
    else:
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        return history


def clear_chat():
    return []


def create_chat_tab():
    with gr.TabItem("ğŸ’¬ èŠå¤©"):
        gr.Markdown("## ğŸ’¬ AIå¯¹è¯")
        gr.Markdown("ä¸AIåŠ©æ‰‹è¿›è¡Œå¯¹è¯ï¼Œæ”¯æŒè®°å¿†æ£€ç´¢å’Œå·¥å…·è°ƒç”¨")

        chat_history = gr.Chatbot(
            label="å¯¹è¯å†å²",
            height=450
        )

        with gr.Row():
            msg_input = gr.Textbox(
                label="è¾“å…¥æ¶ˆæ¯",
                placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...",
                scale=5,
                lines=2
            )
            with gr.Column(scale=1):
                send_btn = gr.Button("å‘é€")
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

        gr.Markdown("*æç¤º: AIä¼šåŸºäºæ‚¨çš„è®°å¿†åº“è¿›è¡Œå›ç­”*")

        send_btn.click(chat_with_ai, [msg_input, chat_history], chat_history)
        msg_input.submit(chat_with_ai, [msg_input, chat_history], chat_history)
        clear_btn.click(clear_chat, None, chat_history)


def create_memory_tab():
    with gr.TabItem("ğŸ§  è®°å¿†ç®¡ç†"):
        gr.Markdown("## ğŸ§  è®°å¿†ç®¡ç†ç³»ç»Ÿ")
        gr.Markdown("ç®¡ç†é•¿æœŸ/çŸ­æœŸ/æ°¸ä¹…è®°å¿†ï¼Œæ”¯æŒä¸‰ç»´è¯„åˆ†æœç´¢ã€è®°å¿†å¬å›å’Œæ‰¹é‡æ“ä½œ")

        with gr.Tabs():
            with gr.TabItem("ğŸ“‹ è®°å¿†åˆ—è¡¨"):
                mem_type_filter = gr.Dropdown(
                    ["all", "long_term", "short_term", "permanent"],
                    label="ç­›é€‰ç±»å‹",
                    value="all"
                )
                refresh_list_btn = gr.Button("åˆ·æ–°åˆ—è¡¨")
                memory_list = gr.Textbox(label="è®°å¿†åˆ—è¡¨", lines=12, interactive=False)
                gr.Markdown("### â• æ·»åŠ è®°å¿†")
                mem_content = gr.Textbox(label="å†…å®¹", lines=3, placeholder="è¾“å…¥è®°å¿†å†…å®¹...")
                mem_type_new = gr.Dropdown(
                    ["long_term", "short_term", "permanent"],
                    label="è®°å¿†ç±»å‹",
                    value="long_term"
                )
                mem_importance = gr.Slider(minimum=1, maximum=5, step=1, label="é‡è¦æ€§", value=3)
                mem_tags = gr.Textbox(label="æ ‡ç­¾ (é€—å·åˆ†éš”)", placeholder="å·¥ä½œ, é‡è¦")
                add_btn = gr.Button("æ·»åŠ è®°å¿†", variant="primary")
                add_result = gr.Textbox(label="æ·»åŠ ç»“æœ", interactive=False)
                gr.Markdown("### ğŸ” æœç´¢è®°å¿†")
                search_query = gr.Textbox(label="æœç´¢å…³é”®è¯", placeholder="è¾“å…¥æœç´¢å†…å®¹...")
                search_type = gr.Dropdown(
                    ["all", "long_term", "short_term", "permanent"],
                    label="è®°å¿†ç±»å‹",
                    value="all"
                )
                search_btn = gr.Button("æœç´¢", variant="primary")
                search_result = gr.Textbox(label="æœç´¢ç»“æœ", lines=10, interactive=False)
                gr.Markdown("### ğŸ—‘ï¸ åˆ é™¤è®°å¿†")
                del_id = gr.Textbox(label="è®°å¿†ID", placeholder="è¾“å…¥è¦åˆ é™¤çš„è®°å¿†ID")
                delete_btn = gr.Button("åˆ é™¤")
                delete_result = gr.Textbox(label="åˆ é™¤ç»“æœ", interactive=False)

            with gr.TabItem("ğŸ” ä¸‰ç»´æœç´¢"):
                gr.Markdown("### ğŸ” ä¸‰ç»´è¯„åˆ†æœç´¢")
                gr.Markdown("åŸºäºé‡è¦æ€§ã€æ—¶é—´ã€ç›¸å…³æ€§ä¸‰ä¸ªç»´åº¦è¿›è¡Œæ™ºèƒ½æœç´¢")
                search_3d_query = gr.Textbox(label="æœç´¢å…³é”®è¯", placeholder="è¾“å…¥æœç´¢å†…å®¹...")
                search_3d_type = gr.Dropdown(
                    ["all", "long_term", "short_term"],
                    label="è®°å¿†ç±»å‹",
                    value="all"
                )
                search_3d_weights = gr.Dropdown(
                    ["default", "importance", "time", "relevance"],
                    label="æƒé‡ç­–ç•¥",
                    value="default"
                )
                search_3d_btn = gr.Button("ä¸‰ç»´æœç´¢", variant="primary")
                search_3d_result = gr.Textbox(label="æœç´¢ç»“æœ", lines=10, interactive=False)

            with gr.TabItem("ğŸ”„ è®°å¿†å¬å›"):
                gr.Markdown("### ğŸ”„ è®°å¿†å¬å›ä¸é‡æ¿€æ´»")
                gr.Markdown("å¬å›è®°å¿†å¹¶å¢å¼ºå…¶æ—¶é—´åˆ†æ•°å’Œæƒ…æ„Ÿåˆ†æ•°")
                recall_id = gr.Textbox(label="è®°å¿†ID", placeholder="è¾“å…¥è¦å¬å›çš„è®°å¿†ID")
                recall_emotion = gr.Slider(minimum=0.0, maximum=1.0, step=0.1, label="æƒ…æ„Ÿå¼ºåº¦", value=0.5)
                recall_btn = gr.Button("å¬å›è®°å¿†", variant="primary")
                recall_result = gr.Textbox(label="å¬å›ç»“æœ", lines=8, interactive=False)

            with gr.TabItem("ğŸ“¦ æ°¸ä¹…è®°å¿†"):
                gr.Markdown("### ğŸ“¦ æ°¸ä¹…è®°å¿†ç®¡ç†")
                gr.Markdown("æ°¸ä¹…è®°å¿†é›¶è¡°å‡ï¼Œé€‚åˆå­˜å‚¨é‡è¦ä¿¡æ¯")
                perm_list_btn = gr.Button("åˆ·æ–°æ°¸ä¹…è®°å¿†åˆ—è¡¨")
                perm_list = gr.Textbox(label="æ°¸ä¹…è®°å¿†", lines=10, interactive=False)
                gr.Markdown("### â• æ·»åŠ æ°¸ä¹…è®°å¿†")
                perm_content = gr.Textbox(label="å†…å®¹", lines=3, placeholder="è¾“å…¥æ°¸ä¹…è®°å¿†å†…å®¹...")
                perm_tags = gr.Textbox(label="æ ‡ç­¾ (é€—å·åˆ†éš”)", placeholder="é‡è¦, ç”¨æˆ·åå¥½")
                perm_emotion = gr.Slider(minimum=0.0, maximum=1.0, step=0.1, label="æƒ…æ„Ÿåˆ†æ•°", value=0.5)
                perm_add_btn = gr.Button("æ·»åŠ æ°¸ä¹…è®°å¿†", variant="primary")
                perm_add_result = gr.Textbox(label="æ·»åŠ ç»“æœ", interactive=False)

            with gr.TabItem("ğŸ“Š æ‰¹é‡æ“ä½œ"):
                gr.Markdown("### ï¿½ æ‰¹é‡æ“ä½œ")
                gr.Markdown("æ‰¹é‡æ·»åŠ ã€æ›´æ–°æˆ–åˆ é™¤è®°å¿†")
                batch_memories_text = gr.Textbox(
                    label="æ‰¹é‡è®°å¿† (JSON)",
                    lines=8,
                    placeholder='[{"content": "è®°å¿†1", "importance": 3}, {"content": "è®°å¿†2", "importance": 4}]',
                    value='[{"content": "ç¤ºä¾‹è®°å¿†1", "importance": 3}, {"content": "ç¤ºä¾‹è®°å¿†2", "importance": 4}]'
                )
                batch_add_btn = gr.Button("æ‰¹é‡æ·»åŠ ", variant="primary")
                batch_result = gr.Textbox(label="æ‰¹é‡æ“ä½œç»“æœ", lines=5, interactive=False)

            with gr.TabItem("ğŸ“‰ è¡°å‡ç»Ÿè®¡"):
                gr.Markdown("### ğŸ“‰ è¡°å‡ç»Ÿè®¡ä¿¡æ¯")
                gr.Markdown("æŸ¥çœ‹è®°å¿†ç³»ç»Ÿçš„è¡°å‡åˆ†å¸ƒå’Œç»Ÿè®¡")
                decay_stats_btn = gr.Button("è·å–è¡°å‡ç»Ÿè®¡")
                decay_stats_result = gr.Textbox(label="è¡°å‡ç»Ÿè®¡", lines=10, interactive=False)

            with gr.TabItem("ğŸ¤– å‰¯æ¨¡å‹å‘½ä»¤"):
                gr.Markdown("### ğŸ¤– å‰¯æ¨¡å‹å‘½ä»¤ç³»ç»Ÿ")
                gr.Markdown("æ‰§è¡Œå‰¯æ¨¡å‹å‘½ä»¤è¿›è¡Œè®°å¿†ç®¡ç†")
                sec_cmds_btn = gr.Button("è·å–å¯ç”¨å‘½ä»¤")
                sec_cmds_result = gr.Textbox(label="å¯ç”¨å‘½ä»¤", lines=10, interactive=False)
                gr.Markdown("### âš¡ æ‰§è¡Œå‘½ä»¤")
                sec_cmd_name = gr.Dropdown(
                    ["summarize_memory", "archive_memory", "cleanup_memories", "analyze_importance",
                     "decay_memories", "get_memory_insights", "batch_process",
                     "summarize_conversation", "extract_key_points", "generate_memory_report"],
                    label="å‘½ä»¤åç§°",
                    value="summarize_memory"
                )
                sec_cmd_params = gr.Textbox(
                    label="å‘½ä»¤å‚æ•° (JSON)",
                    lines=3,
                    placeholder='{"memory_id": 123, "max_length": 200}'
                )
                sec_exec_btn = gr.Button("æ‰§è¡Œå‘½ä»¤", variant="primary")
                sec_exec_result = gr.Textbox(label="æ‰§è¡Œç»“æœ", lines=8, interactive=False)

        refresh_list_btn.click(get_memory_list, [mem_type_filter], memory_list)
        add_btn.click(add_memory, [mem_content, mem_type_new, mem_importance, mem_tags], add_result)
        search_btn.click(search_memories, [search_query, search_type], search_result)
        delete_btn.click(delete_memory, [del_id], delete_result)
        search_3d_btn.click(search_memories_3d, [search_3d_query, search_3d_type, search_3d_weights], search_3d_result)
        recall_btn.click(recall_memory, [recall_id, recall_emotion], recall_result)
        perm_list_btn.click(get_permanent_memories, None, perm_list)
        
        # åˆ›å»ºéšè—ç»„ä»¶æ¥ä¼ é€’å›ºå®šå€¼
        perm_type_hidden = gr.Textbox(value="permanent", visible=False)
        perm_importance_hidden = gr.Number(value=5, visible=False)
        
        perm_add_btn.click(
            add_memory, 
            [perm_content, perm_type_hidden, perm_importance_hidden, perm_tags], 
            perm_add_result
        )
        batch_add_btn.click(batch_add_memories, [batch_memories_text], batch_result)
        decay_stats_btn.click(get_decay_stats, None, decay_stats_result)
        sec_cmds_btn.click(get_secondary_commands, None, sec_cmds_result)
        sec_exec_btn.click(execute_secondary_command, [sec_cmd_name, sec_cmd_params], sec_exec_result)


def create_acp_tab():
    def refresh_agents():
        result = run_async(call_api("/api/acp/agents"))
        if result.get("status") == "success":
            agents = result.get("agents", [])
            if not agents:
                return "æœªå‘ç°Agents"
            return "\n".join([
                f"ğŸ¤– **{a.get('name', 'Unknown')}**\n   åœ°å€: {a.get('host', 'N/A')}:{a.get('port', 0)}\n   çŠ¶æ€: {a.get('status', 'unknown')} | ç‰ˆæœ¬: {a.get('version', 'N/A')}"
                for a in agents
            ])
        return f"è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def refresh_groups():
        result = run_async(call_api("/api/acp/groups"))
        if result.get("status") == "success":
            groups = result.get("groups", [])
            if not groups:
                return "æš‚æ— ç¾¤ç»„"
            return "\n".join([
                f"ğŸ‘¥ **{g.get('name', 'Unknown')}**\n   æˆå‘˜: {len(g.get('members', []))} | åˆ›å»º: {g.get('creator_name', 'Unknown')}\n   ID: {g.get('id', 'N/A')[:8]}..."
                for g in groups
            ])
        return f"è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def refresh_connections():
        result = run_async(call_api("/api/acp/connections"))
        if result.get("status") == "success":
            connections = result.get("connections", [])
            if not connections:
                return "æš‚æ— è¿æ¥"
            return "\n".join([
                f"ğŸ”— **{c.get('remote_agent_name', 'Unknown')}**\n   çŠ¶æ€: {c.get('status', 'unknown')}\n   åœ°å€: {c.get('host', 'N/A')}:{c.get('port', 0)}"
                for c in connections
            ])
        return f"è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def discover_agents(timeout_val: float):
        result = run_async(call_api("/api/acp/discover", {"timeout": timeout_val}, "POST"))
        if result.get("status") == "success":
            count = result.get("scanned_count", 0)
            return f"âœ“ æ‰«æå®Œæˆï¼Œå‘ç° {count} ä¸ªAgents"
        return f"âœ— æ‰«æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def create_group(name: str, description: str, max_members: int):
        result = run_async(call_api("/api/acp/groups", {"name": name, "description": description, "max_members": max_members}, "POST"))
        if result.get("status") == "success":
            return "âœ“ ç¾¤ç»„åˆ›å»ºæˆåŠŸ", ""
        return f"âœ— åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", name

    def join_group(group_id: str):
        if not group_id:
            return "è¯·è¾“å…¥ç¾¤ç»„ID"
        result = run_async(call_api(f"/api/acp/groups/{group_id}/join", method="POST"))
        if result.get("status") == "success":
            return "âœ“ å·²åŠ å…¥ç¾¤ç»„"
        return f"âœ— åŠ å…¥å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def get_stats():
        result = run_async(call_api("/api/acp/stats"))
        if result.get("status") == "success":
            stats = result.get("statistics", {})
            return f"ğŸ¤– Agents: {stats.get('total_agents', 0)} (åœ¨çº¿: {stats.get('online_agents', 0)})\nğŸ‘¥ ç¾¤ç»„: {stats.get('total_groups', 0)}\nğŸ’¬ æ¶ˆæ¯: {stats.get('total_messages', 0)}"
        return "æ— æ³•è·å–ç»Ÿè®¡"

    with gr.TabItem("ğŸ”— ACPäº’è”"):
        gr.Markdown("## ğŸ”— ACP Connect 2.0")
        gr.Markdown("å±€åŸŸç½‘Agentå‘ç°ä¸äº’è” | ç¾¤ç»„é€šè®¯ | æ¶ˆæ¯ä¼ é€’")

        stats_display = gr.Textbox(label="ğŸ“Š ç»Ÿè®¡ä¿¡æ¯", value=get_stats(), interactive=False, lines=2)

        with gr.Tabs():
            with gr.TabItem("ğŸŒ å‘ç°"):
                with gr.Row():
                    timeout_slider = gr.Slider(minimum=1, maximum=30, value=5, label="æ‰«æè¶…æ—¶(ç§’)")
                    discover_btn = gr.Button("ğŸ” æ‰«æç½‘ç»œ", variant="primary")
                discover_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                gr.Markdown("### ğŸ¤– å‘ç°çš„Agents")
                agent_list = gr.Textbox(label="Agents", lines=8, interactive=False)
                refresh_agents_btn = gr.Button("åˆ·æ–°")

                discover_btn.click(discover_agents, [timeout_slider], discover_status)
                discover_btn.click(refresh_agents, None, agent_list)
                refresh_agents_btn.click(refresh_agents, None, agent_list)

            with gr.TabItem("ğŸ”— è¿æ¥"):
                gr.Markdown("### å½“å‰è¿æ¥")
                connection_list = gr.Textbox(label="è¿æ¥åˆ—è¡¨", lines=8, interactive=False)
                refresh_conn_btn = gr.Button("åˆ·æ–°è¿æ¥")
                refresh_conn_btn.click(refresh_connections, None, connection_list)

            with gr.TabItem("ğŸ‘¥ ç¾¤ç»„"):
                with gr.Row():
                    with gr.Column(scale=2):
                        gr.Markdown("### â• åˆ›å»ºç¾¤ç»„")
                        group_name = gr.Textbox(label="ç¾¤ç»„åç§°", placeholder="è¾“å…¥ç¾¤ç»„åç§°")
                        group_desc = gr.Textbox(label="ç¾¤ç»„æè¿°", placeholder="è¾“å…¥ç¾¤ç»„æè¿°")
                        max_members = gr.Slider(minimum=2, maximum=100, value=50, label="æœ€å¤§æˆå‘˜æ•°")
                        create_group_btn = gr.Button("åˆ›å»ºç¾¤ç»„")
                        create_result = gr.Textbox(label="åˆ›å»ºç»“æœ", interactive=False)
                    with gr.Column(scale=2):
                        gr.Markdown("### ğŸšª åŠ å…¥ç¾¤ç»„")
                        join_id = gr.Textbox(label="ç¾¤ç»„ID", placeholder="è¾“å…¥è¦åŠ å…¥çš„ç¾¤ç»„ID")
                        join_btn = gr.Button("åŠ å…¥ç¾¤ç»„")
                        join_result = gr.Textbox(label="æ“ä½œç»“æœ", interactive=False)

                gr.Markdown("### ğŸ“‹ ç¾¤ç»„åˆ—è¡¨")
                group_list = gr.Textbox(label="ç¾¤ç»„", lines=8, interactive=False)
                refresh_groups_btn = gr.Button("åˆ·æ–°ç¾¤ç»„")
                refresh_groups_btn.click(refresh_groups, None, group_list)

                create_group_btn.click(create_group, [group_name, group_desc, max_members], [create_result, group_name])
                join_btn.click(join_group, [join_id], join_result)


def create_context_tab():
    def get_sessions():
        result = run_async(call_api("/api/context/sessions"))
        if result.get("status") == "success":
            sessions = result.get("sessions", [])
            if not sessions:
                return "æš‚æ— ä¼šè¯"
            return "\n".join([
                f"ğŸ’¬ ä¼šè¯ #{s.get('id', 'N/A')[:8]}\n   æ¶ˆæ¯æ•°: {s.get('message_count', 0)} | åˆ›å»º: {s.get('created_at', '')[:10]}"
                for s in sessions
            ])
        return "è·å–å¤±è´¥"

    def get_messages(session_id: str):
        if not session_id:
            return "è¯·è¾“å…¥ä¼šè¯ID"
        result = run_async(call_api(f"/api/context/messages?session_id={session_id}"))
        if result.get("status") == "success":
            messages = result.get("messages", [])
            if not messages:
                return "æš‚æ— æ¶ˆæ¯"
            return "\n".join([
                f"{'ğŸ‘¤' if m.get('role') == 'user' else 'ğŸ¤–'}: {m.get('content', '')[:100]}..."
                for m in messages
            ])
        return f"è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def create_session(workspace_id: str = "default"):
        result = run_async(call_api("/api/context/sessions", {"workspace_id": workspace_id}, "POST"))
        if result.get("status") == "success":
            return f"âœ“ ä¼šè¯åˆ›å»ºæˆåŠŸ (ID: {result.get('session_id', 'N/A')[:8]}...)"
        return f"âœ— åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    with gr.TabItem("ğŸ’­ ä¸Šä¸‹æ–‡"):
        gr.Markdown("## ğŸ’­ ä¸Šä¸‹æ–‡ç®¡ç†")
        gr.Markdown("ç®¡ç†å¯¹è¯ä¼šè¯ | æ¶ˆæ¯å†å² | ä¸Šä¸‹æ–‡çª—å£")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‹ ä¼šè¯åˆ—è¡¨")
                sessions_list = gr.Textbox(label="ä¼šè¯", lines=10, interactive=False)
                refresh_sessions_btn = gr.Button("åˆ·æ–°")
                refresh_sessions_btn.click(get_sessions, None, sessions_list)

            with gr.Column(scale=1):
                gr.Markdown("### ğŸ’¬ æ¶ˆæ¯å†å²")
                session_id_input = gr.Textbox(label="ä¼šè¯ID", placeholder="è¾“å…¥ä¼šè¯ID")
                get_msg_btn = gr.Button("è·å–æ¶ˆæ¯")
                messages_display = gr.Textbox(label="æ¶ˆæ¯", lines=8, interactive=False)

                gr.Markdown("### â• åˆ›å»ºä¼šè¯")
                workspace_input = gr.Textbox(label="å·¥ä½œåŒºID", value="default")
                create_sess_btn = gr.Button("åˆ›å»ºä¼šè¯", variant="primary")
                create_sess_result = gr.Textbox(label="ç»“æœ", interactive=False)

                get_msg_btn.click(get_messages, [session_id_input], messages_display)
                create_sess_btn.click(create_session, [workspace_input], create_sess_result)


def create_tools_tab():
    def get_tools():
        result = run_async(call_api("/api/tools"))
        if result.get("status") == "success":
            tools = result.get("tools", [])
            if not tools:
                return "æš‚æ— å·¥å…·"
            return "\n".join([
                f"ğŸ”§ **{t.get('name', 'Unknown')}**\n   æè¿°: {t.get('description', 'N/A')[:50]}..."
                for t in tools
            ])
        return "è·å–å¤±è´¥"

    def get_mcp_servers():
        result = run_async(call_api("/api/tools/mcp/servers"))
        if result.get("status") == "success":
            servers = result.get("servers", [])
            if not servers:
                return "æš‚æ— MCPæœåŠ¡å™¨"
            return "\n".join([
                f"ğŸ–¥ï¸ **{s.get('name', 'Unknown')}**\n   çŠ¶æ€: {s.get('status', 'unknown')}"
                for s in servers
            ])
        return "è·å–å¤±è´¥"

    def get_plugins():
        result = run_async(call_api("/api/tools/plugins"))
        if result.get("status") == "success":
            plugins = result.get("plugins", [])
            if not plugins:
                return "æš‚æ— æ’ä»¶"
            return "\n".join([
                f"ğŸ”Œ **{p.get('name', 'Unknown')}** v{p.get('version', 'N/A')}"
                for p in plugins
            ])
        return "è·å–å¤±è´¥"

    with gr.TabItem("ğŸ› ï¸ å·¥å…·"):
        gr.Markdown("## ğŸ› ï¸ å·¥å…·ç³»ç»Ÿ")
        gr.Markdown("å·¥å…·æ³¨å†Œè¡¨ | MCPæœåŠ¡å™¨ | æ’ä»¶ç®¡ç†")

        with gr.Tabs():
            with gr.TabItem("ğŸ”§ å·¥å…·"):
                tools_list = gr.Textbox(label="å·²æ³¨å†Œå·¥å…·", lines=10, interactive=False)
                refresh_tools_btn = gr.Button("åˆ·æ–°å·¥å…·åˆ—è¡¨")
                refresh_tools_btn.click(get_tools, None, tools_list)

            with gr.TabItem("ğŸ–¥ï¸ MCP"):
                mcp_list = gr.Textbox(label="MCPæœåŠ¡å™¨", lines=10, interactive=False)
                refresh_mcp_btn = gr.Button("åˆ·æ–°")
                refresh_mcp_btn.click(get_mcp_servers, None, mcp_list)

            with gr.TabItem("ğŸ”Œ æ’ä»¶"):
                plugins_list = gr.Textbox(label="æ’ä»¶", lines=10, interactive=False)
                refresh_plugins_btn = gr.Button("åˆ·æ–°")
                refresh_plugins_btn.click(get_plugins, None, plugins_list)


def create_admin_tab():
    def get_dashboard():
        result = run_async(call_api("/api/admin/dashboard"))
        if result.get("status") == "success":
            dashboard = result.get("dashboard", {})
            mem_stats = dashboard.get("memory", {})
            ctx_stats = dashboard.get("context", {})
            acp_stats = dashboard.get("acp", {})

            return f"""## ğŸ“Š ç³»ç»Ÿä»ªè¡¨ç›˜

### ğŸ§  è®°å¿†ç³»ç»Ÿ
- æ€»è®°å¿†: {mem_stats.get('total', 0)}
- æ°¸ä¹…è®°å¿†: {mem_stats.get('permanent', 0)}
- é•¿æœŸè®°å¿†: {mem_stats.get('by_type', {}).get('long_term', 0)}
- çŸ­æœŸè®°å¿†: {mem_stats.get('by_type', {}).get('short_term', 0)}

### ğŸ’­ ä¸Šä¸‹æ–‡ç³»ç»Ÿ
- ä¼šè¯æ€»æ•°: {ctx_stats.get('total_sessions', 0)}
- æ´»è·ƒä¼šè¯: {ctx_stats.get('active_sessions', 0)}
- æ¶ˆæ¯æ€»æ•°: {ctx_stats.get('total_messages', 0)}

### ğŸ”— ACPäº’è”
- Agents: {acp_stats.get('total_agents', 0)}
- åœ¨çº¿: {acp_stats.get('online_agents', 0)}
- ç¾¤ç»„: {acp_stats.get('total_groups', 0)}
- æ¶ˆæ¯: {acp_stats.get('total_messages', 0)}
"""
        return "è·å–ä»ªè¡¨ç›˜å¤±è´¥"

    def get_health():
        result = run_async(call_api("/api/admin/health"))
        if result.get("status") == "success":
            status = result.get("status", "unknown")
            components = result.get("components", {})
            uptime = result.get("uptime", "N/A")
            return f"""## ğŸ¥ å¥åº·çŠ¶æ€

**æ€»ä½“çŠ¶æ€:** {status.upper()}
**è¿è¡Œæ—¶é—´:** {uptime}

### ç»„ä»¶çŠ¶æ€
- ğŸ§  è®°å¿†: {components.get('memory', 'N/A')}
- ğŸ’­ ä¸Šä¸‹æ–‡: {components.get('context', 'N/A')}
- ğŸ”— ACP: {components.get('acp', 'N/A')}
- ğŸ¤– LLM: {components.get('llm', 'N/A')}
"""
        return "è·å–å¥åº·çŠ¶æ€å¤±è´¥"

    def get_logs(level: str = "INFO", lines: int = 50):
        result = run_async(call_api(f"/api/admin/logs?level={level}&lines={lines}"))
        if result.get("status") == "success":
            logs = result.get("logs", [])
            if not logs:
                return "æš‚æ— æ—¥å¿—"
            return "\n".join(logs[-lines:])
        return f"è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def backup():
        result = run_async(call_api("/api/admin/backup", method="POST"))
        if result.get("status") == "success":
            return f"âœ“ å¤‡ä»½æˆåŠŸ: {result.get('path', 'N/A')}"
        return f"âœ— å¤‡ä»½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    with gr.TabItem("ğŸ“Š ç›‘æ§ç®¡ç†"):
        gr.Markdown("## ğŸ“Š ç³»ç»Ÿç›‘æ§")
        gr.Markdown("ä»ªè¡¨ç›˜ | å¥åº·æ£€æŸ¥ | æ—¥å¿— | å¤‡ä»½")

        with gr.Tabs():
            with gr.TabItem("ğŸ“ˆ ä»ªè¡¨ç›˜"):
                dashboard = gr.Markdown(label="ä»ªè¡¨ç›˜")
                refresh_dash_btn = gr.Button("åˆ·æ–°ä»ªè¡¨ç›˜")
                refresh_dash_btn.click(get_dashboard, None, dashboard)

            with gr.TabItem("ğŸ¥ å¥åº·"):
                health = gr.Markdown(label="å¥åº·çŠ¶æ€")
                refresh_health_btn = gr.Button("åˆ·æ–°")
                refresh_health_btn.click(get_health, None, health)

            with gr.TabItem("ğŸ“‹ æ—¥å¿—"):
                log_level = gr.Dropdown(["DEBUG", "INFO", "WARNING", "ERROR"], label="æ—¥å¿—çº§åˆ«", value="INFO")
                log_lines = gr.Slider(minimum=10, maximum=200, value=50, label="æ˜¾ç¤ºè¡Œæ•°")
                logs_display = gr.Textbox(label="æ—¥å¿—", lines=15, interactive=False)
                refresh_logs_btn = gr.Button("åˆ·æ–°æ—¥å¿—")
                refresh_logs_btn.click(get_logs, [log_level, log_lines], logs_display)

            with gr.TabItem("ğŸ’¾ å¤‡ä»½"):
                gr.Markdown("### æ•°æ®å¤‡ä»½")
                backup_btn = gr.Button("åˆ›å»ºå¤‡ä»½", variant="primary")
                backup_result = gr.Textbox(label="å¤‡ä»½ç»“æœ", interactive=False)
                backup_btn.click(backup, None, backup_result)


def create_settings_tab():
    def get_config():
        try:
            result = run_async(call_api("/api/admin/config"))
            if result.get("status") == "success":
                config = result.get("config", {})
                import json
                return json.dumps(config, indent=2, ensure_ascii=False)
            return json.dumps({"error": "è·å–é…ç½®å¤±è´¥"}, indent=2, ensure_ascii=False)
        except Exception as e:
            import json
            return json.dumps({"error": f"åŠ è½½é…ç½®æ—¶å‡ºé”™: {str(e)}"}, indent=2, ensure_ascii=False)

    def update_config(config_json: str):
        try:
            import json
            config = json.loads(config_json)
            result = run_async(call_api("/api/admin/config", config, "PUT"))
            if result.get("status") == "success":
                return "âœ“ é…ç½®å·²æ›´æ–°ï¼Œè¯·é‡å¯æœåŠ¡ç”Ÿæ•ˆ"
            return f"âœ— æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        except json.JSONDecodeError as e:
            return f"âœ— JSONæ ¼å¼é”™è¯¯: {str(e)}"
        except Exception as e:
            return f"âœ— é”™è¯¯: {str(e)}"

    def validate_config(config_json: str):
        try:
            import json
            config = json.loads(config_json)
            errors = []

            if "llm" in config:
                llm = config["llm"]
                if "provider" not in llm:
                    errors.append("LLM: ç¼ºå°‘ provider")
                if "model" not in llm:
                    errors.append("LLM: ç¼ºå°‘ model")

            if "vector" in config:
                vector = config["vector"]
                if "port" in vector and not isinstance(vector["port"], int):
                    errors.append("Vector: port å¿…é¡»æ˜¯æ•´æ•°")

            if "system" in config:
                system = config["system"]
                if "port" in system and not isinstance(system["port"], int):
                    errors.append("System: port å¿…é¡»æ˜¯æ•´æ•°")

            if errors:
                return "âš ï¸ é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"- {e}" for e in errors)
            return "âœ“ é…ç½®æ ¼å¼æ­£ç¡®"
        except json.JSONDecodeError as e:
            return f"âœ— JSONæ ¼å¼é”™è¯¯: {str(e)}"
        except Exception as e:
            return f"âœ— éªŒè¯é”™è¯¯: {str(e)}"

    def reset_config():
        try:
            import json
            default_config = {
                "llm": {
                    "provider": "ollama",
                    "host": "http://localhost:11434",
                    "model": "llama3.2",
                    "temperature": 0.7,
                    "max_tokens": 4096
                },
                "vector": {
                    "enabled": True,
                    "host": "localhost",
                    "port": 6333,
                    "embedding_model": "nomic-embed-text"
                },
                "acp": {
                    "enabled": True,
                    "agent_id": "cxhms-agent-001",
                    "agent_name": "CXHMS Agent"
                },
                "system": {
                    "host": "0.0.0.0",
                    "port": 8000,
                    "debug": False,
                    "log_level": "INFO"
                }
            }
            return json.dumps(default_config, indent=2, ensure_ascii=False)
        except Exception as e:
            import json
            return json.dumps({"error": f"é‡ç½®é…ç½®å¤±è´¥: {str(e)}"}, indent=2, ensure_ascii=False)

    def update_llm_config(provider: str, host: str, model: str, temperature: float, max_tokens: int):
        config = {
            "llm": {
                "provider": provider,
                "host": host,
                "model": model,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
        }
        result = run_async(call_api("/api/admin/config", config, "PUT"))
        if result.get("status") == "success":
            return "âœ“ LLMé…ç½®å·²æ›´æ–°"
        return f"âœ— æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def update_vector_config(
        enabled: bool, 
        backend: str, 
        milvus_db_path: str, 
        milvus_vector_size: int, 
        qdrant_host: str, 
        qdrant_port: int,
        provider: str,
        ollama_model: str,
        ollama_host: str,
        hf_model: str,
        hf_device: str,
        hf_normalize: bool,
        openai_model: str,
        openai_api_key: str,
        openai_dimensions: int,
        custom_type: str,
        custom_endpoint: str,
        custom_dimensions: int
    ):
        config = {
            "memory": {
                "vector_enabled": enabled,
                "vector_backend": backend,
                "milvus_lite": {
                    "db_path": milvus_db_path,
                    "vector_size": milvus_vector_size
                },
                "qdrant": {
                    "host": qdrant_host,
                    "port": qdrant_port
                }
            },
            "embedding": {
                "provider": provider,
                "ollama": {
                    "model": ollama_model,
                    "host": ollama_host
                },
                "huggingface": {
                    "model": hf_model,
                    "device": hf_device,
                    "normalize": hf_normalize
                },
                "openai": {
                    "model": openai_model,
                    "api_key": openai_api_key,
                    "dimensions": openai_dimensions
                },
                "custom": {
                    "type": custom_type,
                    "endpoint": custom_endpoint,
                    "dimensions": custom_dimensions
                }
            }
        }
        result = run_async(call_api("/api/admin/config", config, "PUT"))
        if result.get("status") == "success":
            return "âœ“ å‘é‡é…ç½®å·²æ›´æ–°"
        return f"âœ— æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def update_acp_config(enabled: bool, agent_id: str, agent_name: str):
        config = {
            "acp": {
                "enabled": enabled,
                "agent_id": agent_id,
                "agent_name": agent_name
            }
        }
        result = run_async(call_api("/api/admin/config", config, "PUT"))
        if result.get("status") == "success":
            return "âœ“ ACPé…ç½®å·²æ›´æ–°"
        return f"âœ— æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    def update_system_config(host: str, port: int, debug: bool, log_level: str):
        config = {
            "system": {
                "host": host,
                "port": int(port),
                "debug": debug,
                "log_level": log_level
            }
        }
        result = run_async(call_api("/api/admin/config", config, "PUT"))
        if result.get("status") == "success":
            return "âœ“ ç³»ç»Ÿé…ç½®å·²æ›´æ–°"
        return f"âœ— æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    with gr.TabItem("âš™ï¸ è®¾ç½®"):
        gr.Markdown("## âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        gr.Markdown("LLMé…ç½® | å‘é‡é…ç½® | ACPé…ç½® | ç³»ç»Ÿé…ç½®")

        with gr.Tabs():
            with gr.TabItem("ğŸ¤– LLMè®¾ç½®"):
                with gr.Row():
                    with gr.Column():
                        llm_provider = gr.Dropdown(
                            ["ollama", "vllm", "openai", "anthropic", "deepseek", "local"],
                            label="Provider",
                            value="ollama"
                        )
                        llm_host = gr.Textbox(label="Host", value="http://localhost:11434")
                        llm_model = gr.Textbox(label="Model", value="llama3.2")
                        llm_temperature = gr.Slider(minimum=0.0, maximum=2.0, step=0.1, label="Temperature", value=0.7)
                        llm_max_tokens = gr.Slider(minimum=512, maximum=8192, step=256, label="Max Tokens", value=4096)
                        llm_save_btn = gr.Button("ä¿å­˜LLMé…ç½®", variant="primary")
                        llm_result = gr.Textbox(label="ç»“æœ", interactive=False)

                llm_save_btn.click(update_llm_config, [llm_provider, llm_host, llm_model, llm_temperature, llm_max_tokens], llm_result)

            with gr.TabItem("ğŸ” å‘é‡è®¾ç½®"):
                gr.Markdown("### å‘é‡å­˜å‚¨é…ç½®")
                gr.Markdown("é€‰æ‹©å¹¶é…ç½®å‘é‡å­˜å‚¨åç«¯")
                
                vector_enabled = gr.Checkbox(label="å¯ç”¨å‘é‡æœç´¢", value=True)
                
                vector_backend = gr.Dropdown(
                    ["milvus_lite", "qdrant"],
                    label="å‘é‡å­˜å‚¨åç«¯",
                    value="milvus_lite"
                )
                
                gr.Markdown("#### Milvus Lite é…ç½®", visible=True)
                milvus_db_path = gr.Textbox(
                    label="æ•°æ®åº“è·¯å¾„", 
                    value="data/milvus_lite.db",
                    visible=True
                )
                milvus_vector_size = gr.Number(
                    label="å‘é‡ç»´åº¦", 
                    value=768, 
                    precision=0,
                    visible=True
                )
                
                gr.Markdown("#### Qdrant é…ç½®", visible=False)
                vector_host = gr.Textbox(
                    label="Host", 
                    value="localhost",
                    visible=False
                )
                vector_port = gr.Number(
                    label="Port", 
                    value=6333, 
                    precision=0,
                    visible=False
                )
                
                gr.Markdown("#### Embedding æ¨¡å‹é…ç½®")
                gr.Markdown("é€‰æ‹©å¹¶é…ç½®Embeddingæ¨¡å‹")
                
                # Embeddingæ¨¡å‹é€‰é¡¹å¡
                with gr.Tabs():
                    with gr.TabItem("ğŸ¤– Ollama Embeddings"):
                        gr.Markdown("ä½¿ç”¨Ollamaæœ¬åœ°Embeddingæ¨¡å‹")
                        ollama_embedding_model = gr.Textbox(
                            label="æ¨¡å‹åç§°", 
                            value="nomic-embed-text",
                            placeholder="ä¾‹å¦‚: nomic-embed-text, mxbai-embed-large"
                        )
                        ollama_embedding_host = gr.Textbox(
                            label="Ollama Host", 
                            value="http://localhost:11434"
                        )
                    
                    with gr.TabItem("ğŸ¤— HuggingFace Embeddings"):
                        gr.Markdown("ä½¿ç”¨HuggingFaceé¢„è®­ç»ƒæ¨¡å‹")
                        hf_embedding_model = gr.Dropdown(
                            [
                                "sentence-transformers/all-MiniLM-L6-v2",
                                "sentence-transformers/all-mpnet-base-v2",
                                "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                                "BAAI/bge-small-en-v1.5",
                                "BAAI/bge-base-en-v1.5",
                                "Thenlie/StreamTivation"
                            ],
                            label="é€‰æ‹©æ¨¡å‹",
                            value="sentence-transformers/all-MiniLM-L6-v2"
                        )
                        hf_embedding_device = gr.Dropdown(
                            ["cpu", "cuda"],
                            label="è¿è¡Œè®¾å¤‡",
                            value="cpu"
                        )
                        hf_embedding_normalize = gr.Checkbox(
                            label="å½’ä¸€åŒ–å‘é‡", 
                            value=True
                        )
                    
                    with gr.TabItem("ğŸŒ OpenAI Embeddings"):
                        gr.Markdown("ä½¿ç”¨OpenAI API Embeddingæ¨¡å‹")
                        openai_embedding_model = gr.Dropdown(
                            ["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"],
                            label="é€‰æ‹©æ¨¡å‹",
                            value="text-embedding-3-small"
                        )
                        openai_embedding_api_key = gr.Textbox(
                            label="API Key", 
                            value="",
                            placeholder="sk-...",
                            type="password"
                        )
                        openai_embedding_dimensions = gr.Number(
                            label="å‘é‡ç»´åº¦ (å¯é€‰)", 
                            value=1536,
                            precision=0
                        )
                    
                    with gr.TabItem("ğŸ“ æœ¬åœ°/è‡ªå®šä¹‰"):
                        gr.Markdown("ä½¿ç”¨æœ¬åœ°è‡ªå®šä¹‰Embeddingæ¨¡å‹")
                        custom_embedding_type = gr.Dropdown(
                            ["api", "local"],
                            label="ç±»å‹",
                            value="api"
                        )
                        custom_embedding_endpoint = gr.Textbox(
                            label="APIç«¯ç‚¹", 
                            value="http://localhost:8001/embed",
                            placeholder="http://localhost:8001/embed"
                        )
                        custom_embedding_dimensions = gr.Number(
                            label="å‘é‡ç»´åº¦", 
                            value=768,
                            precision=0
                        )
                
                # å½“å‰é€‰ä¸­çš„Embeddingæ¨¡å‹ç±»å‹
                embedding_provider = gr.Dropdown(
                    ["ollama", "huggingface", "openai", "custom"],
                    label="å½“å‰ä½¿ç”¨çš„Embeddingæä¾›å•†",
                    value="ollama"
                )
                
                vector_save_btn = gr.Button("ä¿å­˜å‘é‡é…ç½®", variant="primary")
                vector_result = gr.Textbox(label="ç»“æœ", interactive=False)

                def update_vector_backend_visibility(backend):
                    if backend == "milvus_lite":
                        return {
                            milvus_db_path: gr.update(visible=True),
                            milvus_vector_size: gr.update(visible=True),
                            vector_host: gr.update(visible=False),
                            vector_port: gr.update(visible=False)
                        }
                    else:
                        return {
                            milvus_db_path: gr.update(visible=False),
                            milvus_vector_size: gr.update(visible=False),
                            vector_host: gr.update(visible=True),
                            vector_port: gr.update(visible=True)
                        }

                vector_backend.change(
                    update_vector_backend_visibility,
                    [vector_backend],
                    [milvus_db_path, milvus_vector_size, vector_host, vector_port]
                )

                vector_save_btn.click(
                    update_vector_config, 
                    [
                        vector_enabled, 
                        vector_backend, 
                        milvus_db_path, 
                        milvus_vector_size, 
                        vector_host, 
                        vector_port,
                        embedding_provider,
                        ollama_embedding_model,
                        ollama_embedding_host,
                        hf_embedding_model,
                        hf_embedding_device,
                        hf_embedding_normalize,
                        openai_embedding_model,
                        openai_embedding_api_key,
                        openai_embedding_dimensions,
                        custom_embedding_type,
                        custom_embedding_endpoint,
                        custom_embedding_dimensions
                    ], 
                    vector_result
                )

            with gr.TabItem("ğŸ”— ACPè®¾ç½®"):
                with gr.Row():
                    with gr.Column():
                        acp_enabled = gr.Checkbox(label="å¯ç”¨ACP", value=True)
                        acp_agent_id = gr.Textbox(label="Agent ID", value="cxhms-agent-001")
                        acp_agent_name = gr.Textbox(label="Agentåç§°", value="CXHMS Agent")
                        acp_save_btn = gr.Button("ä¿å­˜ACPé…ç½®", variant="primary")
                        acp_result = gr.Textbox(label="ç»“æœ", interactive=False)

                acp_save_btn.click(update_acp_config, [acp_enabled, acp_agent_id, acp_agent_name], acp_result)

            with gr.TabItem("ğŸ’» ç³»ç»Ÿè®¾ç½®"):
                with gr.Row():
                    with gr.Column():
                        system_host = gr.Textbox(label="Host", value="0.0.0.0")
                        system_port = gr.Number(label="Port", value=8000, precision=0)
                        system_debug = gr.Checkbox(label="Debugæ¨¡å¼", value=False)
                        system_log_level = gr.Dropdown(["DEBUG", "INFO", "WARNING", "ERROR"], label="æ—¥å¿—çº§åˆ«", value="INFO")
                        system_save_btn = gr.Button("ä¿å­˜ç³»ç»Ÿé…ç½®", variant="primary")
                        system_result = gr.Textbox(label="ç»“æœ", interactive=False)

                system_save_btn.click(update_system_config, [system_host, system_port, system_debug, system_log_level], system_result)

            with gr.TabItem("ğŸ“ JSONç¼–è¾‘"):
                gr.Markdown("### é«˜çº§é…ç½®ç¼–è¾‘")
                gr.Markdown("ç›´æ¥ç¼–è¾‘å®Œæ•´é…ç½®ï¼ˆJSONæ ¼å¼ï¼‰")

                with gr.Row():
                    refresh_config_btn = gr.Button("ğŸ”„ åˆ·æ–°é…ç½®")
                    validate_config_btn = gr.Button("âœ… éªŒè¯é…ç½®")
                    reset_config_btn = gr.Button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤å€¼")

                config_editor = gr.Code(
                    label="JSONé…ç½®",
                    language="json",
                    lines=20,
                    value=get_config()
                )

                with gr.Row():
                    save_json_btn = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", variant="primary")
                    save_result = gr.Textbox(label="ä¿å­˜ç»“æœ", interactive=False)

                refresh_config_btn.click(get_config, None, config_editor)
                validate_config_btn.click(validate_config, [config_editor], save_result)
                reset_config_btn.click(reset_config, None, config_editor)
                save_json_btn.click(update_config, [config_editor], save_result)


def create_app():
    with gr.Blocks(
        title="CXHMS - AIä»£ç†ä¸­é—´å±‚æœåŠ¡"
    ) as app:
        gr.Markdown("""
        <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 20px;">
            <h1 style="color: white; margin: 0;">ğŸš€ CXHMS - AIä»£ç†ä¸­é—´å±‚æœåŠ¡</h1>
            <p style="color: white; opacity: 0.9; margin: 10px 0 0 0;">CX-O History & Memory Service</p>
        </div>
        """, elem_classes=["main"])

        with gr.Tabs():
            create_chat_tab()
            create_memory_tab()
            create_acp_tab()
            create_context_tab()
            create_tools_tab()
            create_admin_tab()
            create_settings_tab()

        gr.Markdown("---")
        gr.Markdown("*CXHMS v1.0.0 | Powered by Gradio | ğŸ§  è®°å¿†ç®¡ç† | ğŸ”— ACPäº’è” | ğŸ› ï¸ å·¥å…·è°ƒç”¨*")

    return app


if __name__ == "__main__":
    app = create_app()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )
